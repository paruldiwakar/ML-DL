{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emoji Prediction(LSTM/RNN).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPYWOwPly0jmpw9DUsOf7hD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paruldiwakar/ML-DL/blob/master/Emoji_Prediction(LSTM_RNN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIjMp6TZpr4-",
        "colab_type": "code",
        "outputId": "128cf877-c4e3-4b9c-c4b7-c25797f05fa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "!pip install emoji"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n",
            "\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                        | 10kB 29.2MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                 | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã         | 30kB 4.2MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 51kB 2.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.5.4-cp36-none-any.whl size=42176 sha256=a0f964eb01cbab713a241e74bb1339788a951493d06dc257ca65135010a0cc9e\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/a9/0a/4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-0.5.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4RGsXhvq5hw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import emoji"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLZDfBqEq_to",
        "colab_type": "code",
        "outputId": "93835850-aa5d-46b6-8955-2871b84f40af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "emoji.EMOJI_UNICODE.get(':baseball:')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'‚öæ'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lw46a6fhrFNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emoji_dict = {\n",
        "             \"0\":\":growing_heart:\",\n",
        "             \"1\": \":baseball:\",\n",
        "              \"2\":\":grinning_face_with_big_eyes:\",\n",
        "              \"3\":\":disappointed_face:\",\n",
        "              \"4\":\":fork_and_knife:\",\n",
        "              \"5\":\":hundred_points:\",\n",
        "              \"6\":\":fire:\",\n",
        "              \"7\":\":face_blowing_a_kiss:\",\n",
        "              \"8\":\":chestnut:\",\n",
        "              \"9\":\":flexed_biceps:\"\n",
        "\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99PErIeuwiaX",
        "colab_type": "code",
        "outputId": "2e996489-93ba-46f9-e740-bde94f93bbb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "for e in emoji_dict.values():\n",
        "  print(emoji.emojize(e))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "üíó\n",
            "‚öæ\n",
            "üòÉ\n",
            "üòû\n",
            "üç¥\n",
            "üíØ\n",
            "üî•\n",
            "üòò\n",
            "üå∞\n",
            "üí™\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHAKYtMKwuJs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFHwEu5sMeBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir best_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8bCidn_xWuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(\"/train_emoji.csv\",header=None)\n",
        "test = pd.read_csv(\"/test_emoji.csv\",header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsNv0RrdxmQo",
        "colab_type": "code",
        "outputId": "ee6ec428-c17f-4d1e-bae5-5c0b0da43f49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I want to eat\\t</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>he did not answer\\t</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>he got a very nice raise\\t</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>she got me a nice present\\t</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ha ha ha it was so funny\\t</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             0  1\n",
              "0              I want to eat\\t  4\n",
              "1          he did not answer\\t  3\n",
              "2   he got a very nice raise\\t  2\n",
              "3  she got me a nice present\\t  2\n",
              "4   ha ha ha it was so funny\\t  2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cNnOYNMxoUU",
        "colab_type": "code",
        "outputId": "2128b367-0148-42e8-f481-aeb7fdcb5bb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data = train.values\n",
        "data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['never talk to me again', 3, nan, nan],\n",
              "       ['I am proud of your achievements', 2, nan, nan],\n",
              "       ['It is the worst day in my life', 3, nan, nan],\n",
              "       ['Miss you so much', 0, nan, ' [0]'],\n",
              "       ['food is life', 4, nan, nan],\n",
              "       ['I love you mum', 0, nan, nan],\n",
              "       ['Stop saying bullshit', 3, nan, nan],\n",
              "       ['congratulations on your acceptance', 2, nan, nan],\n",
              "       ['The assignment is too long ', 3, nan, nan],\n",
              "       ['I want to go play', 1, nan, ' [3]'],\n",
              "       ['she did not answer my text ', 3, nan, nan],\n",
              "       ['Your stupidity has no limit', 3, nan, nan],\n",
              "       ['how many points did he score', 1, nan, nan],\n",
              "       ['my algorithm performs poorly', 3, nan, nan],\n",
              "       ['I got approved', 2, nan, nan],\n",
              "       ['Stop shouting at me', 3, nan, nan],\n",
              "       ['Sounds like a fun plan ha ha', 2, nan, nan],\n",
              "       ['no one likes him', 3, nan, nan],\n",
              "       ['the game just finished', 1, nan, ' [2]'],\n",
              "       ['I will celebrate soon', 2, nan, nan],\n",
              "       ['So sad you are not coming', 3, nan, nan],\n",
              "       ['She is my dearest love', 0, nan, ' [1]'],\n",
              "       ['Good job', 2, nan, ' [4]'],\n",
              "       ['It was funny lol', 2, nan, nan],\n",
              "       ['candy is life ', 2, nan, nan],\n",
              "       ['The chicago cubs won again', 1, nan, nan],\n",
              "       ['I am hungry', 4, nan, nan],\n",
              "       ['I am so excited to see you after so long', 2, nan, nan],\n",
              "       ['you did well on you exam', 2, nan, nan],\n",
              "       ['lets brunch some day', 4, nan, nan],\n",
              "       ['he is so cute', 0, nan, nan],\n",
              "       ['How dare you ask that', 3, nan, nan],\n",
              "       ['do you want to join me for dinner ', 4, nan, nan],\n",
              "       ['I said yes', 2, nan, nan],\n",
              "       ['she is attractive', 0, nan, nan],\n",
              "       ['you suck', 3, nan, nan],\n",
              "       ['she smiles a lot', 2, nan, nan],\n",
              "       ['he is laughing', 2, nan, nan],\n",
              "       ['she takes forever to get ready ', 3, nan, nan],\n",
              "       ['French macaroon is so tasty', 4, nan, nan],\n",
              "       ['we made it', 2, nan, nan],\n",
              "       ['I am excited', 2, nan, nan],\n",
              "       ['I adore my dogs', 0, nan, nan],\n",
              "       ['Congratulations', 2, nan, nan],\n",
              "       ['this girl was mean', 3, nan, nan],\n",
              "       ['you two are cute', 0, nan, nan],\n",
              "       ['my code is working but the grader gave me zero', 3, nan, nan],\n",
              "       ['this joke is killing me haha', 2, nan, nan],\n",
              "       ['do you like pizza ', 4, nan, nan],\n",
              "       ['you got a down grade', 3, nan, nan],\n",
              "       ['I missed you', 0, nan, nan],\n",
              "       ['I think I will end up alone', 3, nan, nan],\n",
              "       ['I got humiliated by my sister', 3, nan, nan],\n",
              "       ['you are awful', 3, nan, nan],\n",
              "       ['I cooked meat', 4, nan, nan],\n",
              "       ['This is so funny', 2, nan, nan],\n",
              "       ['lets exercise', 1, nan, nan],\n",
              "       ['he is the best player', 1, nan, nan],\n",
              "       ['I am going to the stadium', 1, nan, ' [0]'],\n",
              "       ['You are incredibly intelligent and talented', 2, nan, nan],\n",
              "       ['Stop shouting at me', 3, nan, nan],\n",
              "       ['Who is your favorite player', 1, nan, nan],\n",
              "       ['I like you a lot', 0, nan, nan],\n",
              "       ['i miss him', 0, nan, nan],\n",
              "       ['my dog just had a few puppies', 0, nan, nan],\n",
              "       ['I hate him', 3, nan, nan],\n",
              "       ['I want chinese food', 4, nan, nan],\n",
              "       ['cookies are good', 4, nan, nan],\n",
              "       ['her smile is so charming', 2, nan, nan],\n",
              "       ['Bravo for the announcement it got a lot of traction', 2, nan,\n",
              "        ' [3]'],\n",
              "       ['she plays baseball', 1, nan, nan],\n",
              "       ['he did an amazing job', 2, nan, nan],\n",
              "       ['The baby is adorable', 0, nan, nan],\n",
              "       ['I was waiting for her for two hours ', 3, nan, nan],\n",
              "       ['funny', 2, nan, nan],\n",
              "       ['I like it when people smile', 2, nan, nan],\n",
              "       ['I love dogs', 0, nan, 'v2'],\n",
              "       ['they are so kind and friendly', 0, nan, ' [0]'],\n",
              "       ['So bad that you cannot come with us', 3, nan, nan],\n",
              "       ['he likes baseball', 1, nan, nan],\n",
              "       ['I am so impressed by your dedication to this project', 2, nan,\n",
              "        nan],\n",
              "       ['I am at the baseball game', 1, nan, ' [0]'],\n",
              "       ['Bravo', 2, nan, nan],\n",
              "       ['What a fun moment', 2, nan, nan],\n",
              "       ['I want to have sushi for dinner', 4, nan, nan],\n",
              "       ['I am very disappointed', 3, nan, nan],\n",
              "       ['he can not do anything', 3, nan, nan],\n",
              "       ['lol', 2, nan, nan],\n",
              "       ['Lets have food together', 4, nan, nan],\n",
              "       ['she is so cute', 0, nan, nan],\n",
              "       ['miss you my dear', 0, nan, ' [6]'],\n",
              "       ['I am looking for a date', 0, nan, nan],\n",
              "       ['I am frustrated', 3, nan, nan],\n",
              "       ['I lost my wallet', 3, nan, nan],\n",
              "       ['you failed the midterm', 3, nan, nan],\n",
              "       ['ha ha ha it was so funny', 2, nan, nan],\n",
              "       ['Do you want to give me a hug', 0, nan, nan],\n",
              "       ['who is playing in the final', 1, nan, nan],\n",
              "       ['she is happy', 2, nan, nan],\n",
              "       ['You are not qualified for this position', 3, nan, nan],\n",
              "       ['I love my dad', 0, nan, nan],\n",
              "       ['this guy was such a joke', 2, nan, nan],\n",
              "       ['Good joke', 2, nan, nan],\n",
              "       ['This specialization is great', 2, nan, nan],\n",
              "       ['you could not solve it', 3, nan, nan],\n",
              "       ['I am so happy for you', 2, nan, nan],\n",
              "       ['Congrats on the new job', 2, nan, nan],\n",
              "       ['I am proud of you forever', 2, nan, nan],\n",
              "       ['I want to eat', 4, nan, nan],\n",
              "       ['That catcher sucks ', 1, nan, nan],\n",
              "       ['The first base man got the ball', 1, nan, nan],\n",
              "       ['this is bad', 3, nan, nan],\n",
              "       ['you did not do your homework', 3, nan, nan],\n",
              "       ['I will have a cheese cake', 4, nan, nan],\n",
              "       ['do you have a ball', 1, nan, nan],\n",
              "       ['the lectures are great though ', 2, nan, nan],\n",
              "       ['Are you down for baseball this afternoon', 1, nan, nan],\n",
              "       ['what are the rules of the game', 1, nan, nan],\n",
              "       ['I am always working', 3, nan, nan],\n",
              "       ['where is the stadium', 1, nan, nan],\n",
              "       ['She is the cutest person I have ever seen', 0, nan, ' [4]'],\n",
              "       ['vegetables are healthy', 4, nan, nan],\n",
              "       ['he is handsome', 0, nan, nan],\n",
              "       ['too bad that you were not here', 3, nan, nan],\n",
              "       ['you are a loser', 3, nan, nan],\n",
              "       ['I love indian food', 4, nan, nan],\n",
              "       ['Who is down for a restaurant', 4, nan, nan],\n",
              "       ['he had to make a home run', 1, nan, nan],\n",
              "       ['I am ordering food', 4, nan, nan],\n",
              "       ['What is wrong with you', 3, nan, nan],\n",
              "       ['I love you', 0, nan, nan],\n",
              "       ['great job', 2, nan, nan]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb_v4U3yx97K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = train[0]\n",
        "y_train = train[1]\n",
        "X_test = test[0]\n",
        "y_test = test[1]\n",
        "#X_train[0] =(\" \").join(X_train[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9gN14zuEN5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train,num_classes=5)\n",
        "y_test = to_categorical(y_test,num_classes=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX9t6yUbI07u",
        "colab_type": "code",
        "outputId": "8870e1c1-d08d-4980-9eca-fd142563574a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.shape,y_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((132, 5), (56, 5))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NP6ICN34yJsm",
        "colab_type": "code",
        "outputId": "8f6d0500-7e1e-496a-cda9-a40643a62fee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "for i in range(5):\n",
        "  print(X_train[i],emoji.emojize(emoji_dict[str(y_train[i])]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "never talk to me again üòû\n",
            "I am proud of your achievements üòÉ\n",
            "It is the worst day in my life üòû\n",
            "Miss you so much üíó\n",
            "food is life üç¥\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VUhFU1oyLBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open('/glove.6B.50d.txt',encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0R4fiMA1STA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings_index = {}\n",
        "\n",
        "for line in f:\n",
        "  values = line.split()\n",
        "  word = values[0]\n",
        "  coef = np.asarray(values[1:],dtype='float')\n",
        "\n",
        "  embeddings_index[word] = coef\n",
        "\n",
        "f.close() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6lQAbEY20Ar",
        "colab_type": "code",
        "outputId": "6dde0e15-dc39-408e-b1dd-fe0f49a72c53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "emb_dim = embeddings_index[\"eat\"].shape[0]\n",
        "emb_dim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmpYp3h64HMX",
        "colab_type": "text"
      },
      "source": [
        "### Converting sentences into vectors (like output of embedding layer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PurxH3U34VJS",
        "colab_type": "code",
        "outputId": "b9048773-4a23-415a-b158-d753c4fb10ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "def embedding_out(X):\n",
        "\n",
        "  max_len = 10\n",
        "  embedding_out = np.zeros((X.shape[0],max_len,emb_dim)) \n",
        "  \n",
        "  for ix in range(X.shape[0]): \n",
        "     # to go to every sentence\n",
        "     X[ix] = X[ix].split()\n",
        "\n",
        "     for ij in range(len(X[ix])): \n",
        "       # to go every word in current (ix) sentence \n",
        "\n",
        "       try:\n",
        "         embedding_out[ix][ij] = embeddings_index[X[ix][ij].lower()]\n",
        "\n",
        "       except:\n",
        "         embedding_out[ix][ij] = np.zeros((50,))\n",
        "\n",
        "  return embedding_out\n",
        "\n",
        "embeddings_matrix_train = embedding_out(X_train)  \n",
        "embeddings_matrix_test = embedding_out(X_test)  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S75dK8oZ3ofj",
        "colab_type": "code",
        "outputId": "41801a44-fb7b-4dc8-c89e-66d03378a064",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embeddings_matrix_train.shape,embeddings_matrix_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((132, 10, 50), (56, 10, 50))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02bCEECJF7g6",
        "colab_type": "text"
      },
      "source": [
        "### Define the RNN/LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FL5isumnAObB",
        "colab_type": "code",
        "outputId": "c0f61287-bff6-49eb-d062-104b9215fb11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from tensorflow.python.keras.layers import *\n",
        "from tensorflow.python.keras.layers.advanced_activations import LeakyReLU\n",
        "from tensorflow.python.keras.models import Sequential,Model\n",
        "from tensorflow.compat.v1.keras.optimizers import Adam\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sOGJlq0AQ7a",
        "colab_type": "code",
        "outputId": "c4c39968-814a-4fb2-ed8e-eec0d557c379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(64,input_shape=(10,50),return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64,return_sequences=False))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_6 (LSTM)                (None, 10, 64)            29440     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 10, 64)            0         \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 5)                 325       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 62,789\n",
            "Trainable params: 62,789\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl29K7CXBOTC",
        "colab_type": "code",
        "outputId": "d373aaa4-b1fb-45df-f0da-44487d57f364",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"best_model.h5\",monitor='val_loss',verbose=True,save_best_only=True)\n",
        "earlystop = EarlyStopping(monitor='val_accuracy',patience=5)\n",
        "\n",
        "hist = model.fit(embeddings_matrix_train,y_train,epochs=100,batch_size=64,shuffle=True,validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 105 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "105/105 [==============================] - 0s 5ms/sample - loss: 1.6089 - accuracy: 0.2190 - val_loss: 1.6096 - val_accuracy: 0.2222\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 0s 231us/sample - loss: 1.5506 - accuracy: 0.3238 - val_loss: 1.6179 - val_accuracy: 0.2222\n",
            "Epoch 3/100\n",
            "105/105 [==============================] - 0s 224us/sample - loss: 1.5411 - accuracy: 0.3333 - val_loss: 1.6312 - val_accuracy: 0.2222\n",
            "Epoch 4/100\n",
            "105/105 [==============================] - 0s 255us/sample - loss: 1.4839 - accuracy: 0.3905 - val_loss: 1.6403 - val_accuracy: 0.2222\n",
            "Epoch 5/100\n",
            "105/105 [==============================] - 0s 210us/sample - loss: 1.4855 - accuracy: 0.3810 - val_loss: 1.6494 - val_accuracy: 0.2222\n",
            "Epoch 6/100\n",
            "105/105 [==============================] - 0s 236us/sample - loss: 1.4563 - accuracy: 0.3619 - val_loss: 1.6556 - val_accuracy: 0.2222\n",
            "Epoch 7/100\n",
            "105/105 [==============================] - 0s 230us/sample - loss: 1.4144 - accuracy: 0.4000 - val_loss: 1.6516 - val_accuracy: 0.2222\n",
            "Epoch 8/100\n",
            "105/105 [==============================] - 0s 221us/sample - loss: 1.3972 - accuracy: 0.3429 - val_loss: 1.6274 - val_accuracy: 0.2963\n",
            "Epoch 9/100\n",
            "105/105 [==============================] - 0s 229us/sample - loss: 1.3999 - accuracy: 0.4190 - val_loss: 1.5821 - val_accuracy: 0.2593\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 0s 223us/sample - loss: 1.3632 - accuracy: 0.4857 - val_loss: 1.5350 - val_accuracy: 0.2593\n",
            "Epoch 11/100\n",
            "105/105 [==============================] - 0s 273us/sample - loss: 1.3188 - accuracy: 0.4857 - val_loss: 1.4863 - val_accuracy: 0.2593\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 0s 240us/sample - loss: 1.2693 - accuracy: 0.5524 - val_loss: 1.4315 - val_accuracy: 0.2963\n",
            "Epoch 13/100\n",
            "105/105 [==============================] - 0s 240us/sample - loss: 1.2163 - accuracy: 0.5810 - val_loss: 1.3784 - val_accuracy: 0.3704\n",
            "Epoch 14/100\n",
            "105/105 [==============================] - 0s 214us/sample - loss: 1.1555 - accuracy: 0.6190 - val_loss: 1.3354 - val_accuracy: 0.4444\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 0s 228us/sample - loss: 1.0787 - accuracy: 0.6667 - val_loss: 1.2996 - val_accuracy: 0.3704\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 0s 225us/sample - loss: 1.0612 - accuracy: 0.6571 - val_loss: 1.2596 - val_accuracy: 0.4444\n",
            "Epoch 17/100\n",
            "105/105 [==============================] - 0s 301us/sample - loss: 0.9390 - accuracy: 0.6571 - val_loss: 1.1992 - val_accuracy: 0.5556\n",
            "Epoch 18/100\n",
            "105/105 [==============================] - 0s 229us/sample - loss: 0.8909 - accuracy: 0.7333 - val_loss: 1.1196 - val_accuracy: 0.6667\n",
            "Epoch 19/100\n",
            "105/105 [==============================] - 0s 225us/sample - loss: 0.8146 - accuracy: 0.7429 - val_loss: 1.0323 - val_accuracy: 0.6667\n",
            "Epoch 20/100\n",
            "105/105 [==============================] - 0s 226us/sample - loss: 0.8170 - accuracy: 0.7143 - val_loss: 0.9957 - val_accuracy: 0.6667\n",
            "Epoch 21/100\n",
            "105/105 [==============================] - 0s 228us/sample - loss: 0.6967 - accuracy: 0.8190 - val_loss: 1.0000 - val_accuracy: 0.6667\n",
            "Epoch 22/100\n",
            "105/105 [==============================] - 0s 257us/sample - loss: 0.6586 - accuracy: 0.7619 - val_loss: 1.0323 - val_accuracy: 0.6667\n",
            "Epoch 23/100\n",
            "105/105 [==============================] - 0s 214us/sample - loss: 0.6546 - accuracy: 0.8000 - val_loss: 1.0769 - val_accuracy: 0.6667\n",
            "Epoch 24/100\n",
            "105/105 [==============================] - 0s 231us/sample - loss: 0.5853 - accuracy: 0.8095 - val_loss: 1.0621 - val_accuracy: 0.7037\n",
            "Epoch 25/100\n",
            "105/105 [==============================] - 0s 231us/sample - loss: 0.5727 - accuracy: 0.7905 - val_loss: 0.9694 - val_accuracy: 0.7037\n",
            "Epoch 26/100\n",
            "105/105 [==============================] - 0s 250us/sample - loss: 0.4688 - accuracy: 0.8667 - val_loss: 0.9141 - val_accuracy: 0.6667\n",
            "Epoch 27/100\n",
            "105/105 [==============================] - 0s 225us/sample - loss: 0.5176 - accuracy: 0.8381 - val_loss: 0.9390 - val_accuracy: 0.6296\n",
            "Epoch 28/100\n",
            "105/105 [==============================] - 0s 228us/sample - loss: 0.5085 - accuracy: 0.8095 - val_loss: 0.8877 - val_accuracy: 0.7037\n",
            "Epoch 29/100\n",
            "105/105 [==============================] - 0s 225us/sample - loss: 0.4325 - accuracy: 0.8762 - val_loss: 0.9768 - val_accuracy: 0.7037\n",
            "Epoch 30/100\n",
            "105/105 [==============================] - 0s 228us/sample - loss: 0.4821 - accuracy: 0.8571 - val_loss: 1.0227 - val_accuracy: 0.7407\n",
            "Epoch 31/100\n",
            "105/105 [==============================] - 0s 241us/sample - loss: 0.4240 - accuracy: 0.8667 - val_loss: 1.1023 - val_accuracy: 0.7037\n",
            "Epoch 32/100\n",
            "105/105 [==============================] - 0s 225us/sample - loss: 0.4240 - accuracy: 0.8667 - val_loss: 1.0560 - val_accuracy: 0.7037\n",
            "Epoch 33/100\n",
            "105/105 [==============================] - 0s 227us/sample - loss: 0.3518 - accuracy: 0.8857 - val_loss: 1.0332 - val_accuracy: 0.7037\n",
            "Epoch 34/100\n",
            "105/105 [==============================] - 0s 261us/sample - loss: 0.3191 - accuracy: 0.8857 - val_loss: 0.9814 - val_accuracy: 0.7037\n",
            "Epoch 35/100\n",
            "105/105 [==============================] - 0s 245us/sample - loss: 0.2985 - accuracy: 0.9238 - val_loss: 0.9883 - val_accuracy: 0.6667\n",
            "Epoch 36/100\n",
            "105/105 [==============================] - 0s 226us/sample - loss: 0.2842 - accuracy: 0.9143 - val_loss: 0.9902 - val_accuracy: 0.6667\n",
            "Epoch 37/100\n",
            "105/105 [==============================] - 0s 228us/sample - loss: 0.3007 - accuracy: 0.8952 - val_loss: 0.9543 - val_accuracy: 0.7037\n",
            "Epoch 38/100\n",
            "105/105 [==============================] - 0s 243us/sample - loss: 0.2380 - accuracy: 0.9143 - val_loss: 1.0318 - val_accuracy: 0.6296\n",
            "Epoch 39/100\n",
            "105/105 [==============================] - 0s 283us/sample - loss: 0.2540 - accuracy: 0.9238 - val_loss: 1.1605 - val_accuracy: 0.6296\n",
            "Epoch 40/100\n",
            "105/105 [==============================] - 0s 223us/sample - loss: 0.2266 - accuracy: 0.9333 - val_loss: 1.2385 - val_accuracy: 0.6296\n",
            "Epoch 41/100\n",
            "105/105 [==============================] - 0s 223us/sample - loss: 0.2622 - accuracy: 0.9238 - val_loss: 1.2170 - val_accuracy: 0.6296\n",
            "Epoch 42/100\n",
            "105/105 [==============================] - 0s 232us/sample - loss: 0.1889 - accuracy: 0.9429 - val_loss: 1.3057 - val_accuracy: 0.6296\n",
            "Epoch 43/100\n",
            "105/105 [==============================] - 0s 223us/sample - loss: 0.2319 - accuracy: 0.9048 - val_loss: 1.2641 - val_accuracy: 0.6296\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 0s 226us/sample - loss: 0.1939 - accuracy: 0.9524 - val_loss: 1.1918 - val_accuracy: 0.6296\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 0s 220us/sample - loss: 0.1387 - accuracy: 0.9714 - val_loss: 1.1877 - val_accuracy: 0.6667\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 0s 287us/sample - loss: 0.1892 - accuracy: 0.9429 - val_loss: 1.1441 - val_accuracy: 0.6667\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 0s 219us/sample - loss: 0.1366 - accuracy: 0.9619 - val_loss: 1.1510 - val_accuracy: 0.6667\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 0s 229us/sample - loss: 0.1634 - accuracy: 0.9524 - val_loss: 1.0888 - val_accuracy: 0.6667\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 0s 240us/sample - loss: 0.0782 - accuracy: 1.0000 - val_loss: 1.1981 - val_accuracy: 0.7037\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 0s 236us/sample - loss: 0.1121 - accuracy: 0.9714 - val_loss: 1.2280 - val_accuracy: 0.6667\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 0s 227us/sample - loss: 0.0837 - accuracy: 0.9905 - val_loss: 1.2912 - val_accuracy: 0.5926\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 0s 234us/sample - loss: 0.0581 - accuracy: 1.0000 - val_loss: 1.3786 - val_accuracy: 0.5926\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 0s 219us/sample - loss: 0.0645 - accuracy: 0.9810 - val_loss: 1.3357 - val_accuracy: 0.5926\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 0s 234us/sample - loss: 0.0726 - accuracy: 0.9905 - val_loss: 1.2922 - val_accuracy: 0.6667\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 0s 244us/sample - loss: 0.0633 - accuracy: 0.9905 - val_loss: 1.3108 - val_accuracy: 0.6667\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 0s 242us/sample - loss: 0.0604 - accuracy: 0.9905 - val_loss: 1.3697 - val_accuracy: 0.6296\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 0s 219us/sample - loss: 0.0452 - accuracy: 1.0000 - val_loss: 1.4012 - val_accuracy: 0.6296\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 0s 233us/sample - loss: 0.0596 - accuracy: 0.9810 - val_loss: 1.3350 - val_accuracy: 0.6667\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 0s 231us/sample - loss: 0.0463 - accuracy: 0.9905 - val_loss: 1.4251 - val_accuracy: 0.6667\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 0s 229us/sample - loss: 0.0687 - accuracy: 0.9905 - val_loss: 1.5213 - val_accuracy: 0.6296\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 0s 246us/sample - loss: 0.0551 - accuracy: 0.9810 - val_loss: 1.5771 - val_accuracy: 0.6296\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 0s 250us/sample - loss: 0.0534 - accuracy: 0.9905 - val_loss: 1.5629 - val_accuracy: 0.6296\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 0s 217us/sample - loss: 0.0324 - accuracy: 1.0000 - val_loss: 1.5689 - val_accuracy: 0.6296\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 0s 226us/sample - loss: 0.0413 - accuracy: 0.9905 - val_loss: 1.6078 - val_accuracy: 0.6296\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 0s 229us/sample - loss: 0.0264 - accuracy: 1.0000 - val_loss: 1.7310 - val_accuracy: 0.5926\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 0s 208us/sample - loss: 0.0402 - accuracy: 0.9905 - val_loss: 1.7660 - val_accuracy: 0.5556\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 0s 224us/sample - loss: 0.0428 - accuracy: 1.0000 - val_loss: 1.7589 - val_accuracy: 0.5926\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 0s 233us/sample - loss: 0.0528 - accuracy: 0.9905 - val_loss: 1.7949 - val_accuracy: 0.5926\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 0s 228us/sample - loss: 0.0382 - accuracy: 0.9905 - val_loss: 1.8458 - val_accuracy: 0.5926\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 0s 216us/sample - loss: 0.0413 - accuracy: 0.9905 - val_loss: 1.7703 - val_accuracy: 0.6296\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 0s 224us/sample - loss: 0.0348 - accuracy: 1.0000 - val_loss: 1.6398 - val_accuracy: 0.6667\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 0s 239us/sample - loss: 0.0252 - accuracy: 0.9905 - val_loss: 1.6079 - val_accuracy: 0.6667\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 0s 244us/sample - loss: 0.0215 - accuracy: 1.0000 - val_loss: 1.6524 - val_accuracy: 0.6667\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 0s 248us/sample - loss: 0.0251 - accuracy: 1.0000 - val_loss: 1.7440 - val_accuracy: 0.6667\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 0s 246us/sample - loss: 0.0277 - accuracy: 1.0000 - val_loss: 1.8160 - val_accuracy: 0.6296\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 0s 238us/sample - loss: 0.0220 - accuracy: 1.0000 - val_loss: 1.8812 - val_accuracy: 0.6296\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 0s 238us/sample - loss: 0.0153 - accuracy: 1.0000 - val_loss: 1.9191 - val_accuracy: 0.6296\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 0s 227us/sample - loss: 0.0206 - accuracy: 0.9905 - val_loss: 1.8400 - val_accuracy: 0.6667\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 0s 224us/sample - loss: 0.0170 - accuracy: 1.0000 - val_loss: 1.7850 - val_accuracy: 0.6296\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 0s 235us/sample - loss: 0.0159 - accuracy: 1.0000 - val_loss: 1.7136 - val_accuracy: 0.6296\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 0s 226us/sample - loss: 0.0153 - accuracy: 1.0000 - val_loss: 1.6333 - val_accuracy: 0.6296\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 0s 240us/sample - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.5974 - val_accuracy: 0.6296\n",
            "Epoch 83/100\n",
            "105/105 [==============================] - 0s 285us/sample - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.5824 - val_accuracy: 0.6667\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 0s 240us/sample - loss: 0.0368 - accuracy: 0.9810 - val_loss: 1.4559 - val_accuracy: 0.6667\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 0s 232us/sample - loss: 0.0191 - accuracy: 1.0000 - val_loss: 1.4997 - val_accuracy: 0.6296\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 0s 231us/sample - loss: 0.0225 - accuracy: 1.0000 - val_loss: 1.6749 - val_accuracy: 0.6667\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 0s 246us/sample - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.9410 - val_accuracy: 0.5926\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 0s 221us/sample - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.0770 - val_accuracy: 0.5556\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 0s 222us/sample - loss: 0.0136 - accuracy: 1.0000 - val_loss: 2.0014 - val_accuracy: 0.5185\n",
            "Epoch 90/100\n",
            "105/105 [==============================] - 0s 231us/sample - loss: 0.0186 - accuracy: 0.9905 - val_loss: 2.0474 - val_accuracy: 0.5185\n",
            "Epoch 91/100\n",
            "105/105 [==============================] - 0s 228us/sample - loss: 0.0277 - accuracy: 0.9905 - val_loss: 1.8486 - val_accuracy: 0.5926\n",
            "Epoch 92/100\n",
            "105/105 [==============================] - 0s 259us/sample - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.6852 - val_accuracy: 0.5926\n",
            "Epoch 93/100\n",
            "105/105 [==============================] - 0s 243us/sample - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.5560 - val_accuracy: 0.6667\n",
            "Epoch 94/100\n",
            "105/105 [==============================] - 0s 257us/sample - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.5064 - val_accuracy: 0.6667\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 0s 238us/sample - loss: 0.0494 - accuracy: 0.9905 - val_loss: 1.6134 - val_accuracy: 0.6667\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 0s 233us/sample - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.7544 - val_accuracy: 0.6667\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 0s 229us/sample - loss: 0.0144 - accuracy: 1.0000 - val_loss: 1.8618 - val_accuracy: 0.6296\n",
            "Epoch 98/100\n",
            "105/105 [==============================] - 0s 256us/sample - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.9064 - val_accuracy: 0.5926\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 0s 222us/sample - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.9614 - val_accuracy: 0.5556\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 0s 231us/sample - loss: 0.0231 - accuracy: 1.0000 - val_loss: 1.7883 - val_accuracy: 0.6296\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVBxfRY5BsEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict_classes(embeddings_matrix_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgSf4SNuKDBr",
        "colab_type": "code",
        "outputId": "2ec8c215-1dc7-493f-d6a5-443627cab28b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4 3 2 2 2 2 3 2 2 2 1 2 0 3 1 3 2 2 3 2 0 0 4 2 3 3 2 0 1 2 0 1 0 2 0 1 2\n",
            " 4 4 2 1 0 0 2 2 2 2 2 0 1 1 0 3 2 2 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaghufSyKFij",
        "colab_type": "code",
        "outputId": "d6e1baa0-e271-4756-d309-ba8a61b4b6ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.evaluate(embeddings_matrix_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4346551895141602, 0.71428573]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YV9to3mAMXPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"best_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m3rzwQOKQAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"best_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjJcF4ItPMae",
        "colab_type": "code",
        "outputId": "d766c1cd-c71e-48ea-c9e4-f25a83ba50eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(30):\n",
        "  print(' '.join(X_test[i]))\n",
        "  print(emoji.emojize(emoji_dict[str(np.argmax(y_test[i]))]))\n",
        "  print(emoji.emojize(emoji_dict[str(pred[i])]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I want to eat\n",
            "üç¥\n",
            "üç¥\n",
            "he did not answer\n",
            "üòû\n",
            "üòû\n",
            "he got a very nice raise\n",
            "üòÉ\n",
            "üòÉ\n",
            "she got me a nice present\n",
            "üòÉ\n",
            "üòÉ\n",
            "ha ha ha it was so funny\n",
            "üòÉ\n",
            "üòÉ\n",
            "he is a good friend\n",
            "üòÉ\n",
            "üòÉ\n",
            "I am upset\n",
            "üòû\n",
            "üòû\n",
            "We had such a lovely dinner tonight\n",
            "üòÉ\n",
            "üòÉ\n",
            "where is the food\n",
            "üç¥\n",
            "üòÉ\n",
            "Stop making this joke ha ha ha\n",
            "üòÉ\n",
            "üòÉ\n",
            "where is the ball\n",
            "‚öæ\n",
            "‚öæ\n",
            "work is hard\n",
            "üòû\n",
            "üòÉ\n",
            "This girl is messing with me\n",
            "üòû\n",
            "üíó\n",
            "are you serious\n",
            "üòû\n",
            "üòû\n",
            "Let us go play baseball\n",
            "‚öæ\n",
            "‚öæ\n",
            "This stupid grader is not working\n",
            "üòû\n",
            "üòû\n",
            "work is horrible\n",
            "üòû\n",
            "üòÉ\n",
            "Congratulation for having a baby\n",
            "üòÉ\n",
            "üòÉ\n",
            "stop pissing me off\n",
            "üòû\n",
            "üòû\n",
            "any suggestions for dinner\n",
            "üç¥\n",
            "üòÉ\n",
            "I love taking breaks\n",
            "üíó\n",
            "üíó\n",
            "you brighten my day\n",
            "üòÉ\n",
            "üíó\n",
            "I boiled rice\n",
            "üç¥\n",
            "üç¥\n",
            "she is a bully\n",
            "üòû\n",
            "üòÉ\n",
            "Why are you feeling bad\n",
            "üòû\n",
            "üòû\n",
            "I am upset\n",
            "üòû\n",
            "üòû\n",
            "give me the ball\n",
            "‚öæ\n",
            "üòÉ\n",
            "My grandmother is the love of my life\n",
            "üíó\n",
            "üíó\n",
            "enjoy your game\n",
            "‚öæ\n",
            "‚öæ\n",
            "valentine day is near\n",
            "üòÉ\n",
            "üòÉ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2ioyyCYTVaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}